{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO INSTALL\n",
    "# Ollama, ollama pull <required model>\n",
    "# Pandoc, Miktex (for transfer markdown to PDF). If you just need markdown file, don't need to install them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pypandoc\n",
    "import re\n",
    "pypandoc.download_pandoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "\n",
    "Goal: Take anonymized audio notes and generate a structured report based on the extracted information. The report should resemble clinical notes as closely as possible, containing patient information, FINDINGS, and comments.\n",
    "\n",
    "You will be provided with the following examples:\n",
    "\n",
    "Four anonymized clinical notes from sonography sessions\n",
    "Corresponding anonymized audio notes (Note: Audio recordings may contain less information than the clinical notes).\n",
    "\n",
    "\n",
    "anonymized audio note1: Early pregnancy LMP 4th October 2024 EDD 11th July 2025 D5 week 6 days Single intrauterine gestational sac is seen Fetal pole is not seen yet YAC sac seen Decidual reaction present No membrane separation is seen MHD 1.45 mm 1.45 cm Maturity 5 weeks 5 days Right over in normal Left over in odd scene History of removal noted\n",
    "\n",
    "clinical note1: NAME:  DATE- 14 NOV 2024 SEX: FEMALE AGE: 31 YRS REF. BY:  UHID NO: 62576/ OP D EXAMINATION: GRAV IDU TERU S LMP- 04/10/2024 D- 5 W ks 6 Days EDD- 11/07/2025 FINDINGS:  The grav id uterus show' s smooth walled gestation al sac.  A yolk sac is seen. Foetal pole is not seen yet.  Decidual reaction seen.  No. membrane separation is seen.  MS D- 1.45 m D- 5 W ks 5 Days Right ovary normal.  Left ovary not seen. H/ O removal.  No aden ex al pathology seen.  No free fluid is seen in POD.  Comments: Early intra uterine pregnancy of age- 5 w ks 5 days\n",
    "\n",
    "anonymized audio note2: liver is normal both kidney are normal in size and echo and both ureter are not dilated urinary bladder is well distended no calculus or mass seen uterus is normal in size the myometrial and endometrial echo are normal the endometrial cavity is empty ET 6 mm both ovaries are normal and minimal free fluid in lower abdomen\n",
    "\n",
    "clinical note2: Name Date- 04 Dec 2024 Sex Female Age- 19 Yrs Ref. By Uni. ID- 86451/ IPD Examination: USG of Abdomen and Pelvis Findings:  The liver appears normal in size and echo. No focal or diffuse lesion is seen.  NoI HBR dilatation is seen. The portal and hepatic veins are normal.  The gall bladder is distended. No calculus or mass is seen. The wall thickness is normal.  CBD is of normal caliber.  Spleen is of normal size and echo. No focal or diffuse lesion seen.  Pancreas is normal in echo. The pancreatic duct is not dilated.  Both kidneys are normal in size and echo. The CM differentiation is preserved. No calculus or hydrone phrosis is seen. No perinephric pathology seen.  RK- 90 x 40 mm PT- 12 mm LK- 99 x 44 mm PT- 14 mm Both the ureters are not dilated.  Urinary bladder is well distended. No calculus or mass is seen.  Uterus is normal in size. The myometrial and endometrial echo are normal. The endometrial cavity is empty. ET- 6 mm.  Both ovaries are normal. No aden exal pathology is seen.  No lymph nodes seen. No obvious bowel lesion seen.  There is a minimal free fluid is seen in lower abdomen.  Comments:  Minimal free fluid in lower abdomen.  Clinical correlation and followup\n",
    "\n",
    "anonymized audio note3:  Single live intrauterine fetus is seen in URTEX presentation. Fetal cardiac activity and movements are appreciated. FHR 136 per minute, LICAR is less, AFI 8.6 cm, placenta is posterior, left lateral, 3 vessel cord is seen. called a scene the PD 8.66 HC 32.7 AC 30.6 T FL 6.62 HL 6.07 average 35 plus 2 weight 2 4 6 9 color Doppler examination within normal limits mild oligohydronius\n",
    "\n",
    "clinical note3: NAME:  DATE: 13 DEC 2024 SEX/ AGE: FEMALE/ 30 YRS REF. BY:  EXAM: OBSTETRICS USG LMP- 07/04/2024 D- 35 W KS 5 DAYS ED D- 12/01/2025 FINDINGS:  Single live intra ture r in e foe tus is seen in vertex presentation.  The foe tal cardiac activity and movements are appreciated. F HR- 136/ bpm.  Liquor is less. AFI- 8.6 cm.  Placenta is posterior, left lateral.  Three vessel cord is seen.  No obvious congenital anomalies are seen in the present foetal position.  Detection of anomalies depends upon the gestational age, foetal position.  amount of liquor and maternal abdominal wall thickness. Not all anomalies are detected on USG. Gender evaluation is not done as per the P CP ND T law.  The foetal parameters areas follows-  BPD 8.66 cm.  HC 32.70 cm.  AC 30.60 cm.  FL 6.62 cm.  HL 6.07 cm.  Average gestational age- 35 w ks 2 days EFB W- 2469 gm s± 10%  ART ER Y PI RI S/ D Umbilical 1.00 0.63 2.74 Right uter in e 0.61 0.40 1.67 Left uter in e 0.84 0.55 2.20 MCA 1.45 0.79 4.84 COMMENTS:  Single intra ture r in e foetus in vertex presentation with average gestational age of 35 w ks 2 days Less liquor.\n",
    "\n",
    "anonymized audio note4:  Pelvic Ultrasound Examination Uterus is bulky, globular and shows adenomyotic changes Majors 8.5 x 6.34 x 5.7 cm Endometrial equal central and normal, ET 6.6 Both ovaries normal, no adenoxyl pathology, no free fluid is seen in pouch of Douglas Adenomyosis uterus\n",
    "\n",
    "clinical note4: NAME SEX:  FEMALE DATE: 03 JAN 2024 REF. BY:  AGE: 22 YRS EXAMINATION: GRAV I DU TERU S UH ID NO: 80768/ OP D LMP- 15/11/2024 D- 7 W ks ED D- 22/08/2025 FINDINGS:  The gravid uterus shows smooth walled gestation al sac.  A foetal pole is seen.  Cardiac activity is appreciated.  Decidual reaction is good.  C RL- 3 mm D- 5 W ks 6 Days Tiny blood collection seen just above internal os, measuring 5.9 x 2.8 mm.  CER VIX- 4 cms No aden exal pathology seen.  No free fluid is seen in POD.  Comments:  Early intra uterine pregnancy of age- 5 W ks 6 Days Delayed conception. USG ED D- 30/08/2025 Tiny blood collection just above internal os.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m client.api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mgenerate_gpt\u001b[39m(query):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_client.py:114\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    112\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    116\u001b[39m     )\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_gpt(query):\n",
    "    \n",
    "    prompt = context\n",
    "    prompt += f\"\\n\\nTesting anonymized audio note: {query}\\n\\n\"\n",
    "    prompt += \"Give me the corresponding report with Markdown style.\\n\"\n",
    "    prompt += \"Do not give me any output that does not conform to Markdown format.\\n\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "def generate_ollama(query, model_name):\n",
    "\n",
    "    prompt = context\n",
    "    prompt += f\"\\n\\nTesting anonymized audio note: {query}\\n\\n\"\n",
    "    prompt += \"Give me the corresponding report with a clear Markdown style, for Testing anonymized audio note.\\n\"\n",
    "    prompt += \"The Markdown report starts with '$$$$$$' and ends with '@@@@@@'.\\n\"\n",
    "    response: ChatResponse = chat(model=model_name, messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "      },\n",
    "    ])\n",
    "\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_markdown_content(text):\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    start_index = next((i for i, line in enumerate(lines) if \"$$$$$$\" in line), None)\n",
    "    end_index = next((i for i, line in enumerate(lines) if \"@@@@@@\" in line), None)\n",
    "\n",
    "    if end_index is not None:\n",
    "        lines = lines[:end_index]    \n",
    "    if start_index is not None:\n",
    "        lines = lines[start_index + 1:]\n",
    "\n",
    "    return '\\n'.join(lines).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_gpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m./anonymized/5.wav.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m      3\u001b[39m     content = file.read()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m output = \u001b[43mgenerate_gpt\u001b[49m(content)\n\u001b[32m      6\u001b[39m output = output.replace(\u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33moutput_gpt-4o-mini.md\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_gpt' is not defined"
     ]
    }
   ],
   "source": [
    "# Need OPENAI_API_KEY in environment path\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "output = generate_gpt(content)\n",
    "output = output.replace(\"```\", '').replace(\"markdown\", '')\n",
    "\n",
    "with open(\"output_gpt-4o-mini.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "pypandoc.convert_file(\"output_gpt-4o-mini.md\", \"pdf\", outputfile=\"output_gpt-4o-mini.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama3-8b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "output = generate_ollama(content, 'llama3:8b')\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "with open(\"output_llama3-8b.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "pypandoc.convert_file(\"output_llama3-8b.md\", \"pdf\", outputfile=\"output_llama3-8b.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for updates as a MiKTeX user.\n",
      "pdflatex: major issue: So far, you have not checked for updates as a MiKTeX user.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qwen2.5:7b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'qwen2.5:7b'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for updates as a MiKTeX user.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phi4:latest\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'phi4:latest'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qwen2.5:14b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'qwen2.5:14b'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thewindmom/llama3-med42-8b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'thewindmom/llama3-med42-8b'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace('/', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# monotykamary/medichat-llama3\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'monotykamary/medichat-llama3'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace('/', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# medllama2:latest \n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'medllama2'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with BioBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using dmis-lab/biobert-base-cased-v1.1: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for BioBERT: output_biobert.md, output_biobert.pdf\n",
      "Processing with ClinicalBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using emilyalsentzer/Bio_ClinicalBERT: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for ClinicalBERT: output_clinicalbert.md, output_clinicalbert.pdf\n",
      "Processing with PubMedBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for PubMedBERT: output_pubmedbert.md, output_pubmedbert.pdf\n",
      "Processing with GatorTron...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MegatronBertForTokenClassification were not initialized from the model checkpoint at UFNLP/gatortron-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using UFNLP/gatortron-base: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for GatorTron: output_gatortron.md, output_gatortron.pdf\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import pypandoc\n",
    "import re\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# Download Pandoc if not already installed\n",
    "pypandoc.download_pandoc()\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define context for Ollama prompt\n",
    "context = '''\n",
    "Goal: Take anonymized audio notes and generate a structured report based on the extracted information. The report should resemble clinical notes as closely as possible, containing patient information, FINDINGS, and comments.\n",
    "\n",
    "You will be provided with the following examples:\n",
    "\n",
    "Four anonymized clinical notes from sonography sessions\n",
    "Corresponding anonymized audio notes (Note: Audio recordings may contain less information than the clinical notes).\n",
    "\n",
    "anonymized audio note1: Early pregnancy LMP 4th October 2024 EDD 11th July 2025 D5 week 6 days Single intrauterine gestational sac is seen Fetal pole is not seen yet YAC sac seen Decidual reaction present No membrane separation is seen MHD 1.45 mm 1.45 cm Maturity 5 weeks 5 days Right over in normal Left over in odd scene History of removal noted\n",
    "\n",
    "clinical note1: NAME:  DATE- 14 NOV 2024 SEX: FEMALE AGE: 31 YRS REF. BY:  UHID NO: 62576/ OP D EXAMINATION: GRAV IDU TERU S LMP- 04/10/2024 D- 5 W ks 6 Days EDD- 11/07/2025 FINDINGS:  The grav id uterus show' s smooth walled gestation al sac.  A yolk sac is seen. Foetal pole is not seen yet.  Decidual reaction seen.  No. membrane separation is seen.  MS D- 1.45 m D- 5 W ks 5 Days Right ovary normal.  Left ovary not seen. H/ O removal.  No aden ex al pathology seen.  No free fluid is seen in POD.  Comments: Early intra uterine pregnancy of age- 5 w ks 5 days\n",
    "\n",
    "anonymized audio note2: liver is normal both kidney are normal in size and echo and both ureter are not dilated urinary bladder is well distended no calculus or mass seen uterus is normal in size the myometrial and endometrial echo are normal the endometrial cavity is empty ET 6 mm both ovaries are normal and minimal free fluid in lower abdomen\n",
    "\n",
    "clinical note2: Name Date- 04 Dec 2024 Sex Female Age- 19 Yrs Ref. By Uni. ID- 86451/ IPD Examination: USG of Abdomen and Pelvis Findings:  The liver appears normal in size and echo. No focal or diffuse lesion is seen.  NoI HBR dilatation is seen. The portal and hepatic veins are normal.  The gall bladder is distended. No calculus or mass is seen. The wall thickness is normal.  CBD is of normal caliber.  Spleen is of normal size and echo. No focal or diffuse lesion seen.  Pancreas is normal in echo. The pancreatic duct is not dilated.  Both kidneys are normal in size and echo. The CM differentiation is preserved. No calculus or hydrone phrosis is seen. No perinephric pathology seen.  RK- 90 x 40 mm PT- 12 mm LK- 99 x 44 mm PT- 14 mm Both the ureters are not dilated.  Urinary bladder is well distended. No calculus or mass is seen.  Uterus is normal in size. The myometrial and endometrial echo are normal. The endometrial cavity is empty. ET- 6 mm.  Both ovaries are normal. No aden exal pathology is seen.  No lymph nodes seen. No obvious bowel lesion seen.  There is a minimal free fluid is seen in lower abdomen.  Comments:  Minimal free fluid in lower abdomen.  Clinical correlation and followup\n",
    "\n",
    "anonymized audio note3:  Single live intrauterine fetus is seen in URTEX presentation. Fetal cardiac activity and movements are appreciated. FHR 136 per minute, LICAR is less, AFI 8.6 cm, placenta is posterior, left lateral, 3 vessel cord is seen. called a scene the PD 8.66 HC 32.7 AC 30.6 T FL 6.62 HL 6.07 average 35 plus 2 weight 2 4 6 9 color Doppler examination within normal limits mild oligohydronius\n",
    "\n",
    "clinical note3: NAME:  DATE: 13 DEC 2024 SEX/ AGE: FEMALE/ 30 YRS REF. BY:  EXAM: OBSTETRICS USG LMP- 07/04/2024 D- 35 W KS 5 DAYS ED D- 12/01/2025 FINDINGS:  Single live intra ture r in e foe tus is seen in vertex presentation.  The foe tal cardiac activity and movements are appreciated. F HR- 136/ bpm.  Liquor is less. AFI- 8.6 cm.  Placenta is posterior, left lateral.  Three vessel cord is seen.  No obvious congenital anomalies are seen in the present foetal position.  Detection of anomalies depends upon the gestational age, foetal position.  amount of liquor and maternal abdominal wall thickness. Not all anomalies are detected on USG. Gender evaluation is not done as per the P CP ND T law.  The foetal parameters areas follows-  BPD 8.66 cm.  HC 32.70 cm.  AC 30.60 cm.  FL 6.62 cm.  HL 6.07 cm.  Average gestational age- 35 w ks 2 days EFB W- 2469 gm s± 10%  ART ER Y PI RI S/ D Umbilical 1.00 0.63 2.74 Right uter in e 0.61 0.40 1.67 Left uter in e 0.84 0.55 2.20 MCA 1.45 0.79 4.84 COMMENTS:  Single intra ture r in e foetus in vertex presentation with average gestational age of 35 w ks 2 days Less liquor.\n",
    "\n",
    "anonymized audio note4:  Pelvic Ultrasound Examination Uterus is bulky, globular and shows adenomyotic changes Majors 8.5 x 6.34 x 5.7 cm Endometrial equal central and normal, ET 6.6 Both ovaries normal, no adenoxyl pathology, no free fluid is seen in pouch of Douglas Adenomyosis uterus\n",
    "\n",
    "clinical note4: NAME SEX:  FEMALE DATE: 03 JAN 2024 REF. BY:  AGE: 22 YRS EXAMINATION: GRAV I DU TERU S UH ID NO: 80768/ OP D LMP- 15/11/2024 D- 7 W ks ED D- 22/08/2025 FINDINGS:  The gravid uterus shows smooth walled gestation al sac.  A foetal pole is seen.  Cardiac activity is appreciated.  Decidual reaction is good.  C RL- 3 mm D- 5 W ks 6 Days Tiny blood collection seen just above internal os, measuring 5.9 x 2.8 mm.  CER VIX- 4 cms No aden exal pathology seen.  No free fluid is seen in POD.  Comments:  Early intra uterine pregnancy of age- 5 W ks 6 Days Delayed conception. USG ED D- 30/08/2025 Tiny blood collection just above internal os.\n",
    "'''\n",
    "\n",
    "# Function to preprocess transcript text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    text = text.lower()  # Convert to lowercase for consistency\n",
    "    return text\n",
    "\n",
    "# Function to extract entities using BERT-based models (BioBERT, ClinicalBERT, PubMedBERT)\n",
    "def extract_entities_with_bert(text, model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "    # Preprocess the text\n",
    "    text = preprocess_text(text)\n",
    "    \n",
    "    # Perform NER\n",
    "    entities = nlp(text)\n",
    "    \n",
    "    # Post-process entities into a structured format\n",
    "    extracted_entities = []\n",
    "    current_entity = \"\"\n",
    "    current_label = \"\"\n",
    "    \n",
    "    for entity in entities:\n",
    "        word = entity['word'].replace(\"##\", \"\")  # Handle subword tokens\n",
    "        if entity['entity'].startswith('B-'):\n",
    "            if current_entity:\n",
    "                extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "            current_entity = word\n",
    "            current_label = entity['entity'][2:]  # Remove 'B-' prefix\n",
    "        elif entity['entity'].startswith('I-') and current_label == entity['entity'][2:]:\n",
    "            current_entity += \" \" + word\n",
    "        else:\n",
    "            if current_entity:\n",
    "                extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "            current_entity = \"\"\n",
    "            current_label = \"\"\n",
    "\n",
    "    if current_entity:\n",
    "        extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "\n",
    "    return extracted_entities\n",
    "\n",
    "# Function to generate structured report using Ollama (LLaMA 3)\n",
    "def generate_ollama(query, entities, model_name):\n",
    "    prompt = context\n",
    "    prompt += f\"\\n\\nTesting anonymized audio note: {query}\\n\\n\"\n",
    "    prompt += f\"Extracted entities by BERT model: {entities}\\n\\n\"\n",
    "    prompt += \"Give me the corresponding report with a clear Markdown style, for Testing anonymized audio note.\\n\"\n",
    "    prompt += \"The Markdown report starts with '$$$$$$' and ends with '@@@@@@'.\\n\"\n",
    "    response: ChatResponse = chat(model=model_name, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        },\n",
    "    ])\n",
    "\n",
    "    return response.message.content\n",
    "\n",
    "# Function to clean Markdown content\n",
    "def clean_markdown_content(text):\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    start_index = next((i for i, line in enumerate(lines) if \"$$$$$$\" in line), None)\n",
    "    end_index = next((i for i, line in enumerate(lines) if \"@@@@@@\" in line), None)\n",
    "\n",
    "    if end_index is not None:\n",
    "        lines = lines[:end_index]    \n",
    "    if start_index is not None:\n",
    "        lines = lines[start_index + 1:]\n",
    "\n",
    "    return '\\n'.join(lines).strip()\n",
    "\n",
    "# Main pipeline to process transcript, extract entities, and generate report\n",
    "def process_transcript(transcript_file, bert_model_name, ollama_model_name, output_md_file, output_pdf_file):\n",
    "    # Read the transcript file\n",
    "    with open(transcript_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Step 1: Extract entities using BERT-based model\n",
    "    entities = extract_entities_with_bert(content, bert_model_name)\n",
    "    print(f\"Extracted entities using {bert_model_name}: {entities}\")\n",
    "\n",
    "    # Step 2: Generate structured report using Ollama\n",
    "    output = generate_ollama(content, entities, ollama_model_name)\n",
    "    output = clean_markdown_content(output)\n",
    "\n",
    "    # Save the Markdown output\n",
    "    with open(output_md_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output)\n",
    "\n",
    "    # Convert Markdown to PDF\n",
    "    pypandoc.convert_file(output_md_file, \"pdf\", outputfile=output_pdf_file)\n",
    "\n",
    "# Define BERT models to use\n",
    "bert_models = {\n",
    "    \"BioBERT\": \"dmis-lab/biobert-base-cased-v1.1\",\n",
    "    \"ClinicalBERT\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"PubMedBERT\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    \"GatorTron\": \"UFNLP/gatortron-base\"\n",
    "}\n",
    "\n",
    "# Run the pipeline for each BERT model\n",
    "transcript_file = \"./anonymized/5.wav.txt\"  # Adjust path to your transcript file\n",
    "ollama_model = \"llama3:8b\"\n",
    "\n",
    "for bert_name, bert_model_name in bert_models.items():\n",
    "    output_md_file = f\"output_{bert_name.lower()}.md\"\n",
    "    output_pdf_file = f\"output_{bert_name.lower()}.pdf\"\n",
    "    print(f\"Processing with {bert_name}...\")\n",
    "    process_transcript(transcript_file, bert_model_name, ollama_model, output_md_file, output_pdf_file)\n",
    "    print(f\"Generated report for {bert_name}: {output_md_file}, {output_pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
