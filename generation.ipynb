{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO INSTALL\n",
    "# Ollama, ollama pull <required model>\n",
    "# Pandoc, Miktex (for transfer markdown to PDF). If you just need markdown file, don't need to install them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kedar\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpypandoc\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mpypandoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_pandoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pypandoc\\pandoc_download.py:231\u001b[39m, in \u001b[36mdownload_pandoc\u001b[39m\u001b[34m(url, targetfolder, version, delete_installer, download_folder)\u001b[39m\n\u001b[32m    228\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLinux pandoc is only compiled for 64bit. Got arch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00march\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# get pandoc_urls\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m pandoc_urls, _ = \u001b[43m_get_pandoc_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pf \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pandoc_urls:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt handle your platform (only Linux, Mac OS X, Windows).\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pypandoc\\pandoc_download.py:49\u001b[39m, in \u001b[36m_get_pandoc_urls\u001b[39m\u001b[34m(version)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# try to open the url\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     response = \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     version_url_frags = response.url.split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m     version = version_url_frags[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:553\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    551\u001b[39m     http_err = \u001b[32m0\u001b[39m\n\u001b[32m    552\u001b[39m args = (\u001b[38;5;28mdict\u001b[39m, proto, meth_name) + args\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:745\u001b[39m, in \u001b[36mHTTPRedirectHandler.http_error_302\u001b[39m\u001b[34m(self, req, fp, code, msg, headers)\u001b[39m\n\u001b[32m    742\u001b[39m fp.read()\n\u001b[32m    743\u001b[39m fp.close()\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\urllib\\request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     r = \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1350\u001b[39m     h.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\http\\client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pypandoc\n",
    "import re\n",
    "pypandoc.download_pandoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "\n",
    "Goal: Take anonymized audio notes and generate a structured report based on the extracted information. The report should resemble clinical notes as closely as possible, containing patient information, FINDINGS, and comments.\n",
    "\n",
    "You will be provided with the following examples:\n",
    "\n",
    "Four anonymized clinical notes from sonography sessions\n",
    "Corresponding anonymized audio notes (Note: Audio recordings may contain less information than the clinical notes).\n",
    "\n",
    "\n",
    "anonymized audio note1: Early pregnancy LMP 4th October 2024 EDD 11th July 2025 D5 week 6 days Single intrauterine gestational sac is seen Fetal pole is not seen yet YAC sac seen Decidual reaction present No membrane separation is seen MHD 1.45 mm 1.45 cm Maturity 5 weeks 5 days Right over in normal Left over in odd scene History of removal noted\n",
    "\n",
    "clinical note1: NAME:  DATE- 14 NOV 2024 SEX: FEMALE AGE: 31 YRS REF. BY:  UHID NO: 62576/ OP D EXAMINATION: GRAV IDU TERU S LMP- 04/10/2024 D- 5 W ks 6 Days EDD- 11/07/2025 FINDINGS:  The grav id uterus show' s smooth walled gestation al sac.  A yolk sac is seen. Foetal pole is not seen yet.  Decidual reaction seen.  No. membrane separation is seen.  MS D- 1.45 m D- 5 W ks 5 Days Right ovary normal.  Left ovary not seen. H/ O removal.  No aden ex al pathology seen.  No free fluid is seen in POD.  Comments: Early intra uterine pregnancy of age- 5 w ks 5 days\n",
    "\n",
    "anonymized audio note2: liver is normal both kidney are normal in size and echo and both ureter are not dilated urinary bladder is well distended no calculus or mass seen uterus is normal in size the myometrial and endometrial echo are normal the endometrial cavity is empty ET 6 mm both ovaries are normal and minimal free fluid in lower abdomen\n",
    "\n",
    "clinical note2: Name Date- 04 Dec 2024 Sex Female Age- 19 Yrs Ref. By Uni. ID- 86451/ IPD Examination: USG of Abdomen and Pelvis Findings:  The liver appears normal in size and echo. No focal or diffuse lesion is seen.  NoI HBR dilatation is seen. The portal and hepatic veins are normal.  The gall bladder is distended. No calculus or mass is seen. The wall thickness is normal.  CBD is of normal caliber.  Spleen is of normal size and echo. No focal or diffuse lesion seen.  Pancreas is normal in echo. The pancreatic duct is not dilated.  Both kidneys are normal in size and echo. The CM differentiation is preserved. No calculus or hydrone phrosis is seen. No perinephric pathology seen.  RK- 90 x 40 mm PT- 12 mm LK- 99 x 44 mm PT- 14 mm Both the ureters are not dilated.  Urinary bladder is well distended. No calculus or mass is seen.  Uterus is normal in size. The myometrial and endometrial echo are normal. The endometrial cavity is empty. ET- 6 mm.  Both ovaries are normal. No aden exal pathology is seen.  No lymph nodes seen. No obvious bowel lesion seen.  There is a minimal free fluid is seen in lower abdomen.  Comments:  Minimal free fluid in lower abdomen.  Clinical correlation and followup\n",
    "\n",
    "anonymized audio note3:  Single live intrauterine fetus is seen in URTEX presentation. Fetal cardiac activity and movements are appreciated. FHR 136 per minute, LICAR is less, AFI 8.6 cm, placenta is posterior, left lateral, 3 vessel cord is seen. called a scene the PD 8.66 HC 32.7 AC 30.6 T FL 6.62 HL 6.07 average 35 plus 2 weight 2 4 6 9 color Doppler examination within normal limits mild oligohydronius\n",
    "\n",
    "clinical note3: NAME:  DATE: 13 DEC 2024 SEX/ AGE: FEMALE/ 30 YRS REF. BY:  EXAM: OBSTETRICS USG LMP- 07/04/2024 D- 35 W KS 5 DAYS ED D- 12/01/2025 FINDINGS:  Single live intra ture r in e foe tus is seen in vertex presentation.  The foe tal cardiac activity and movements are appreciated. F HR- 136/ bpm.  Liquor is less. AFI- 8.6 cm.  Placenta is posterior, left lateral.  Three vessel cord is seen.  No obvious congenital anomalies are seen in the present foetal position.  Detection of anomalies depends upon the gestational age, foetal position.  amount of liquor and maternal abdominal wall thickness. Not all anomalies are detected on USG. Gender evaluation is not done as per the P CP ND T law.  The foetal parameters areas follows-  BPD 8.66 cm.  HC 32.70 cm.  AC 30.60 cm.  FL 6.62 cm.  HL 6.07 cm.  Average gestational age- 35 w ks 2 days EFB W- 2469 gm s± 10%  ART ER Y PI RI S/ D Umbilical 1.00 0.63 2.74 Right uter in e 0.61 0.40 1.67 Left uter in e 0.84 0.55 2.20 MCA 1.45 0.79 4.84 COMMENTS:  Single intra ture r in e foetus in vertex presentation with average gestational age of 35 w ks 2 days Less liquor.\n",
    "\n",
    "anonymized audio note4:  Pelvic Ultrasound Examination Uterus is bulky, globular and shows adenomyotic changes Majors 8.5 x 6.34 x 5.7 cm Endometrial equal central and normal, ET 6.6 Both ovaries normal, no adenoxyl pathology, no free fluid is seen in pouch of Douglas Adenomyosis uterus\n",
    "\n",
    "clinical note4: NAME SEX:  FEMALE DATE: 03 JAN 2024 REF. BY:  AGE: 22 YRS EXAMINATION: GRAV I DU TERU S UH ID NO: 80768/ OP D LMP- 15/11/2024 D- 7 W ks ED D- 22/08/2025 FINDINGS:  The gravid uterus shows smooth walled gestation al sac.  A foetal pole is seen.  Cardiac activity is appreciated.  Decidual reaction is good.  C RL- 3 mm D- 5 W ks 6 Days Tiny blood collection seen just above internal os, measuring 5.9 x 2.8 mm.  CER VIX- 4 cms No aden exal pathology seen.  No free fluid is seen in POD.  Comments:  Early intra uterine pregnancy of age- 5 W ks 6 Days Delayed conception. USG ED D- 30/08/2025 Tiny blood collection just above internal os.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m client.api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mgenerate_gpt\u001b[39m(query):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\_client.py:114\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    112\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    116\u001b[39m     )\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_gpt(query):\n",
    "    \n",
    "    prompt = context\n",
    "    prompt += f\"\\n\\nTesting anonymized audio note: {query}\\n\\n\"\n",
    "    prompt += \"Give me the corresponding report with Markdown style.\\n\"\n",
    "    prompt += \"Do not give me any output that does not conform to Markdown format.\\n\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "def generate_ollama(query, model_name):\n",
    "\n",
    "    prompt = context\n",
    "    prompt += f\"\\n\\nTesting anonymized audio note: {query}\\n\\n\"\n",
    "    prompt += \"Give me the corresponding report with a clear Markdown style, for Testing anonymized audio note.\\n\"\n",
    "    prompt += \"The Markdown report starts with '$$$$$$' and ends with '@@@@@@'.\\n\"\n",
    "    response: ChatResponse = chat(model=model_name, messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "      },\n",
    "    ])\n",
    "\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_markdown_content(text):\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    start_index = next((i for i, line in enumerate(lines) if \"$$$$$$\" in line), None)\n",
    "    end_index = next((i for i, line in enumerate(lines) if \"@@@@@@\" in line), None)\n",
    "\n",
    "    if end_index is not None:\n",
    "        lines = lines[:end_index]    \n",
    "    if start_index is not None:\n",
    "        lines = lines[start_index + 1:]\n",
    "\n",
    "    return '\\n'.join(lines).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_gpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m./anonymized/5.wav.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m      3\u001b[39m     content = file.read()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m output = \u001b[43mgenerate_gpt\u001b[49m(content)\n\u001b[32m      6\u001b[39m output = output.replace(\u001b[33m\"\u001b[39m\u001b[33m```\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33moutput_gpt-4o-mini.md\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_gpt' is not defined"
     ]
    }
   ],
   "source": [
    "# Need OPENAI_API_KEY in environment path\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "output = generate_gpt(content)\n",
    "output = output.replace(\"```\", '').replace(\"markdown\", '')\n",
    "\n",
    "with open(\"output_gpt-4o-mini.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "pypandoc.convert_file(\"output_gpt-4o-mini.md\", \"pdf\", outputfile=\"output_gpt-4o-mini.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama3-8b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "output = generate_ollama(content, 'llama3:8b')\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "with open(\"output_llama3-8b.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "pypandoc.convert_file(\"output_llama3-8b.md\", \"pdf\", outputfile=\"output_llama3-8b.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for updates as a MiKTeX user.\n",
      "pdflatex: major issue: So far, you have not checked for updates as a MiKTeX user.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qwen2.5:7b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'qwen2.5:7b'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for updates as a MiKTeX user.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phi4:latest\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'phi4:latest'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qwen2.5:14b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'qwen2.5:14b'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thewindmom/llama3-med42-8b\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'thewindmom/llama3-med42-8b'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace('/', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# monotykamary/medichat-llama3\n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'monotykamary/medichat-llama3'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace('/', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# medllama2:latest \n",
    "with open(\"./anonymized/5.wav.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "model_name = 'medllama2'\n",
    "output = generate_ollama(content, model_name)\n",
    "output = clean_markdown_content(output)\n",
    "\n",
    "markdown_name = f\"output_{model_name.replace(':', '-')}.md\"\n",
    "with open(markdown_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "PDF_name = markdown_name.replace('.md', '.pdf')\n",
    "pypandoc.convert_file(markdown_name, \"pdf\", outputfile=PDF_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with BioBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kedar\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kedar\\.cache\\huggingface\\hub\\models--dmis-lab--biobert-base-cased-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using dmis-lab/biobert-base-cased-v1.1: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for BioBERT: output_biobert.md, output_biobert.pdf\n",
      "Processing with ClinicalBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kedar\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kedar\\.cache\\huggingface\\hub\\models--emilyalsentzer--Bio_ClinicalBERT. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using emilyalsentzer/Bio_ClinicalBERT: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for ClinicalBERT: output_clinicalbert.md, output_clinicalbert.pdf\n",
      "Processing with PubMedBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kedar\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kedar\\.cache\\huggingface\\hub\\models--microsoft--BiomedNLP-PubMedBERT-base-uncased-abstract. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n",
      "C:\\Users\\kedar\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kedar\\.cache\\huggingface\\hub\\models--UFNLP--gatortron-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for PubMedBERT: output_pubmedbert.md, output_pubmedbert.pdf\n",
      "Processing with GatorTron...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MegatronBertForTokenClassification were not initialized from the model checkpoint at UFNLP/gatortron-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities using UFNLP/gatortron-base: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for GatorTron: output_gatortron.md, output_gatortron.pdf\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import pypandoc\n",
    "import re\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# Download Pandoc if not already installed\n",
    "pypandoc.download_pandoc()\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define context for Ollama prompt\n",
    "context = '''\n",
    "Goal: Take anonymized audio notes and generate a structured report based on the extracted information. The report should resemble clinical notes as closely as possible, containing patient information, FINDINGS, and comments.\n",
    "\n",
    "You will be provided with the following examples:\n",
    "\n",
    "Four anonymized clinical notes from sonography sessions\n",
    "Corresponding anonymized audio notes (Note: Audio recordings may contain less information than the clinical notes).\n",
    "\n",
    "anonymized audio note1: Early pregnancy LMP 4th October 2024 EDD 11th July 2025 D5 week 6 days Single intrauterine gestational sac is seen Fetal pole is not seen yet YAC sac seen Decidual reaction present No membrane separation is seen MHD 1.45 mm 1.45 cm Maturity 5 weeks 5 days Right over in normal Left over in odd scene History of removal noted\n",
    "\n",
    "clinical note1: NAME:  DATE- 14 NOV 2024 SEX: FEMALE AGE: 31 YRS REF. BY:  UHID NO: 62576/ OP D EXAMINATION: GRAV IDU TERU S LMP- 04/10/2024 D- 5 W ks 6 Days EDD- 11/07/2025 FINDINGS:  The grav id uterus show' s smooth walled gestation al sac.  A yolk sac is seen. Foetal pole is not seen yet.  Decidual reaction seen.  No. membrane separation is seen.  MS D- 1.45 m D- 5 W ks 5 Days Right ovary normal.  Left ovary not seen. H/ O removal.  No aden ex al pathology seen.  No free fluid is seen in POD.  Comments: Early intra uterine pregnancy of age- 5 w ks 5 days\n",
    "\n",
    "anonymized audio note2: liver is normal both kidney are normal in size and echo and both ureter are not dilated urinary bladder is well distended no calculus or mass seen uterus is normal in size the myometrial and endometrial echo are normal the endometrial cavity is empty ET 6 mm both ovaries are normal and minimal free fluid in lower abdomen\n",
    "\n",
    "clinical note2: Name Date- 04 Dec 2024 Sex Female Age- 19 Yrs Ref. By Uni. ID- 86451/ IPD Examination: USG of Abdomen and Pelvis Findings:  The liver appears normal in size and echo. No focal or diffuse lesion is seen.  NoI HBR dilatation is seen. The portal and hepatic veins are normal.  The gall bladder is distended. No calculus or mass is seen. The wall thickness is normal.  CBD is of normal caliber.  Spleen is of normal size and echo. No focal or diffuse lesion seen.  Pancreas is normal in echo. The pancreatic duct is not dilated.  Both kidneys are normal in size and echo. The CM differentiation is preserved. No calculus or hydrone phrosis is seen. No perinephric pathology seen.  RK- 90 x 40 mm PT- 12 mm LK- 99 x 44 mm PT- 14 mm Both the ureters are not dilated.  Urinary bladder is well distended. No calculus or mass is seen.  Uterus is normal in size. The myometrial and endometrial echo are normal. The endometrial cavity is empty. ET- 6 mm.  Both ovaries are normal. No aden exal pathology is seen.  No lymph nodes seen. No obvious bowel lesion seen.  There is a minimal free fluid is seen in lower abdomen.  Comments:  Minimal free fluid in lower abdomen.  Clinical correlation and followup\n",
    "\n",
    "anonymized audio note3:  Single live intrauterine fetus is seen in URTEX presentation. Fetal cardiac activity and movements are appreciated. FHR 136 per minute, LICAR is less, AFI 8.6 cm, placenta is posterior, left lateral, 3 vessel cord is seen. called a scene the PD 8.66 HC 32.7 AC 30.6 T FL 6.62 HL 6.07 average 35 plus 2 weight 2 4 6 9 color Doppler examination within normal limits mild oligohydronius\n",
    "\n",
    "clinical note3: NAME:  DATE: 13 DEC 2024 SEX/ AGE: FEMALE/ 30 YRS REF. BY:  EXAM: OBSTETRICS USG LMP- 07/04/2024 D- 35 W KS 5 DAYS ED D- 12/01/2025 FINDINGS:  Single live intra ture r in e foe tus is seen in vertex presentation.  The foe tal cardiac activity and movements are appreciated. F HR- 136/ bpm.  Liquor is less. AFI- 8.6 cm.  Placenta is posterior, left lateral.  Three vessel cord is seen.  No obvious congenital anomalies are seen in the present foetal position.  Detection of anomalies depends upon the gestational age, foetal position.  amount of liquor and maternal abdominal wall thickness. Not all anomalies are detected on USG. Gender evaluation is not done as per the P CP ND T law.  The foetal parameters areas follows-  BPD 8.66 cm.  HC 32.70 cm.  AC 30.60 cm.  FL 6.62 cm.  HL 6.07 cm.  Average gestational age- 35 w ks 2 days EFB W- 2469 gm s± 10%  ART ER Y PI RI S/ D Umbilical 1.00 0.63 2.74 Right uter in e 0.61 0.40 1.67 Left uter in e 0.84 0.55 2.20 MCA 1.45 0.79 4.84 COMMENTS:  Single intra ture r in e foetus in vertex presentation with average gestational age of 35 w ks 2 days Less liquor.\n",
    "\n",
    "anonymized audio note4:  Pelvic Ultrasound Examination Uterus is bulky, globular and shows adenomyotic changes Majors 8.5 x 6.34 x 5.7 cm Endometrial equal central and normal, ET 6.6 Both ovaries normal, no adenoxyl pathology, no free fluid is seen in pouch of Douglas Adenomyosis uterus\n",
    "\n",
    "clinical note4: NAME SEX:  FEMALE DATE: 03 JAN 2024 REF. BY:  AGE: 22 YRS EXAMINATION: GRAV I DU TERU S UH ID NO: 80768/ OP D LMP- 15/11/2024 D- 7 W ks ED D- 22/08/2025 FINDINGS:  The gravid uterus shows smooth walled gestation al sac.  A foetal pole is seen.  Cardiac activity is appreciated.  Decidual reaction is good.  C RL- 3 mm D- 5 W ks 6 Days Tiny blood collection seen just above internal os, measuring 5.9 x 2.8 mm.  CER VIX- 4 cms No aden exal pathology seen.  No free fluid is seen in POD.  Comments:  Early intra uterine pregnancy of age- 5 W ks 6 Days Delayed conception. USG ED D- 30/08/2025 Tiny blood collection just above internal os.\n",
    "'''\n",
    "\n",
    "# Function to preprocess transcript text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    text = text.lower()  # Convert to lowercase for consistency\n",
    "    return text\n",
    "\n",
    "# Function to extract entities using BERT-based models (BioBERT, ClinicalBERT, PubMedBERT)\n",
    "def extract_entities_with_bert(text, model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "    # Preprocess the text\n",
    "    text = preprocess_text(text)\n",
    "    \n",
    "    # Perform NER\n",
    "    entities = nlp(text)\n",
    "    \n",
    "    # Post-process entities into a structured format\n",
    "    extracted_entities = []\n",
    "    current_entity = \"\"\n",
    "    current_label = \"\"\n",
    "    \n",
    "    for entity in entities:\n",
    "        word = entity['word'].replace(\"##\", \"\")  # Handle subword tokens\n",
    "        if entity['entity'].startswith('B-'):\n",
    "            if current_entity:\n",
    "                extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "            current_entity = word\n",
    "            current_label = entity['entity'][2:]  # Remove 'B-' prefix\n",
    "        elif entity['entity'].startswith('I-') and current_label == entity['entity'][2:]:\n",
    "            current_entity += \" \" + word\n",
    "        else:\n",
    "            if current_entity:\n",
    "                extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "            current_entity = \"\"\n",
    "            current_label = \"\"\n",
    "\n",
    "    if current_entity:\n",
    "        extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "\n",
    "    return extracted_entities\n",
    "\n",
    "# Function to generate structured report using Ollama (LLaMA 3)\n",
    "def generate_ollama(query, entities, model_name):\n",
    "    prompt = context\n",
    "    prompt += f\"\\n\\nTesting anonymized audio note: {query}\\n\\n\"\n",
    "    prompt += f\"Extracted entities by BERT model: {entities}\\n\\n\"\n",
    "    prompt += \"Give me the corresponding report with a clear Markdown style, for Testing anonymized audio note.\\n\"\n",
    "    prompt += \"The Markdown report starts with '$$$$$$' and ends with '@@@@@@'.\\n\"\n",
    "    response: ChatResponse = chat(model=model_name, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        },\n",
    "    ])\n",
    "\n",
    "    return response.message.content\n",
    "\n",
    "# Function to clean Markdown content\n",
    "def clean_markdown_content(text):\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    start_index = next((i for i, line in enumerate(lines) if \"$$$$$$\" in line), None)\n",
    "    end_index = next((i for i, line in enumerate(lines) if \"@@@@@@\" in line), None)\n",
    "\n",
    "    if end_index is not None:\n",
    "        lines = lines[:end_index]    \n",
    "    if start_index is not None:\n",
    "        lines = lines[start_index + 1:]\n",
    "\n",
    "    return '\\n'.join(lines).strip()\n",
    "\n",
    "# Main pipeline to process transcript, extract entities, and generate report\n",
    "def process_transcript(transcript_file, bert_model_name, ollama_model_name, output_md_file, output_pdf_file):\n",
    "    # Read the transcript file\n",
    "    with open(transcript_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Step 1: Extract entities using BERT-based model\n",
    "    entities = extract_entities_with_bert(content, bert_model_name)\n",
    "    print(f\"Extracted entities using {bert_model_name}: {entities}\")\n",
    "\n",
    "    # Step 2: Generate structured report using Ollama\n",
    "    output = generate_ollama(content, entities, ollama_model_name)\n",
    "    output = clean_markdown_content(output)\n",
    "\n",
    "    # Save the Markdown output\n",
    "    with open(output_md_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output)\n",
    "\n",
    "    # Convert Markdown to PDF\n",
    "    pypandoc.convert_file(output_md_file, \"pdf\", outputfile=output_pdf_file)\n",
    "\n",
    "# Define BERT models to use\n",
    "bert_models = {\n",
    "    \"BioBERT\": \"dmis-lab/biobert-base-cased-v1.1\",\n",
    "    \"ClinicalBERT\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"PubMedBERT\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    \"GatorTron\": \"UFNLP/gatortron-base\"\n",
    "}\n",
    "\n",
    "# Run the pipeline for each BERT model\n",
    "transcript_file = \"./anonymized/5.wav.txt\"  # Adjust path to your transcript file\n",
    "ollama_model = \"phi4:latest\"\n",
    "\n",
    "for bert_name, bert_model_name in bert_models.items():\n",
    "    output_md_file = f\"output_{bert_name.lower()}.md\"\n",
    "    output_pdf_file = f\"output_{bert_name.lower()}.pdf\"\n",
    "    print(f\"Processing with {bert_name}...\")\n",
    "    process_transcript(transcript_file, bert_model_name, ollama_model, output_md_file, output_pdf_file)\n",
    "    print(f\"Generated report for {bert_name}: {output_md_file}, {output_pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Processing with ClinicalBERT-NER...\n",
      "Processing transcript:  Early Obstetrics Sonography LMP 15th November 2024 EDD 22nd August 2025 D7 weeks Gravid uterus shows smooth wall, gestational sac, fetal pole is seen Cardiac activity is appreciated, decedial reaction good, CRL 3 mm, 5 weeks 6 days Tiny blood collection is seen just above internal loss measuring 5.9 x 2.8 mm, cervix 4 cm No adenexal pathology, no free fluid is seen in pouch of Douglas Delayed conception, UIGDD 30 August 2025\n",
      "Raw NER output from d4data/biomedical-ner-all: [{'entity': 'B-Diagnostic_procedure', 'score': np.float32(0.97903675), 'index': 1, 'word': 'early', 'start': 0, 'end': 5}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.97754467), 'index': 2, 'word': 'ob', 'start': 6, 'end': 8}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9923229), 'index': 3, 'word': '##ste', 'start': 8, 'end': 11}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9717552), 'index': 4, 'word': '##trics', 'start': 11, 'end': 16}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9981511), 'index': 5, 'word': 'son', 'start': 17, 'end': 20}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9994716), 'index': 6, 'word': '##ography', 'start': 20, 'end': 27}, {'entity': 'B-Diagnostic_procedure', 'score': np.float32(0.99709463), 'index': 7, 'word': 'l', 'start': 28, 'end': 29}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9964378), 'index': 8, 'word': '##mp', 'start': 29, 'end': 31}, {'entity': 'B-Date', 'score': np.float32(0.9859509), 'index': 9, 'word': '15th', 'start': 32, 'end': 36}, {'entity': 'I-Date', 'score': np.float32(0.99799913), 'index': 10, 'word': 'november', 'start': 37, 'end': 45}, {'entity': 'I-Date', 'score': np.float32(0.9996698), 'index': 11, 'word': '202', 'start': 46, 'end': 49}, {'entity': 'I-Date', 'score': np.float32(0.9988096), 'index': 12, 'word': '##4', 'start': 49, 'end': 50}, {'entity': 'B-Diagnostic_procedure', 'score': np.float32(0.99477863), 'index': 13, 'word': 'ed', 'start': 51, 'end': 53}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9664198), 'index': 14, 'word': '##d', 'start': 53, 'end': 54}, {'entity': 'B-Date', 'score': np.float32(0.9961104), 'index': 15, 'word': '22nd', 'start': 55, 'end': 59}, {'entity': 'I-Date', 'score': np.float32(0.99910116), 'index': 16, 'word': 'august', 'start': 60, 'end': 66}, {'entity': 'I-Date', 'score': np.float32(0.99973994), 'index': 17, 'word': '202', 'start': 67, 'end': 70}, {'entity': 'I-Date', 'score': np.float32(0.9997743), 'index': 18, 'word': '##5', 'start': 70, 'end': 71}, {'entity': 'I-Date', 'score': np.float32(0.69067067), 'index': 19, 'word': 'd', 'start': 72, 'end': 73}, {'entity': 'I-Date', 'score': np.float32(0.9995845), 'index': 20, 'word': '##7', 'start': 73, 'end': 74}, {'entity': 'I-Date', 'score': np.float32(0.9990202), 'index': 21, 'word': 'weeks', 'start': 75, 'end': 80}, {'entity': 'B-History', 'score': np.float32(0.26914826), 'index': 23, 'word': '##avi', 'start': 83, 'end': 86}, {'entity': 'B-Biological_structure', 'score': np.float32(0.99305665), 'index': 25, 'word': 'ut', 'start': 88, 'end': 90}, {'entity': 'I-Biological_structure', 'score': np.float32(0.45344636), 'index': 26, 'word': '##erus', 'start': 90, 'end': 94}, {'entity': 'B-Biological_structure', 'score': np.float32(0.6169458), 'index': 32, 'word': '##station', 'start': 116, 'end': 123}, {'entity': 'I-Biological_structure', 'score': np.float32(0.9292475), 'index': 33, 'word': '##al', 'start': 123, 'end': 125}, {'entity': 'B-Biological_structure', 'score': np.float32(0.9657499), 'index': 36, 'word': 'fetal', 'start': 131, 'end': 136}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.55304307), 'index': 37, 'word': 'pole', 'start': 137, 'end': 141}, {'entity': 'B-Diagnostic_procedure', 'score': np.float32(0.70790213), 'index': 45, 'word': 'dec', 'start': 183, 'end': 186}, {'entity': 'I-Sign_symptom', 'score': np.float32(0.79191315), 'index': 46, 'word': '##ed', 'start': 186, 'end': 188}, {'entity': 'I-Sign_symptom', 'score': np.float32(0.7702168), 'index': 47, 'word': '##ial', 'start': 188, 'end': 191}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9198804), 'index': 48, 'word': 'reaction', 'start': 192, 'end': 200}, {'entity': 'B-Diagnostic_procedure', 'score': np.float32(0.99864084), 'index': 51, 'word': 'cr', 'start': 207, 'end': 209}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9956487), 'index': 52, 'word': '##l', 'start': 209, 'end': 210}, {'entity': 'B-Lab_value', 'score': np.float32(0.9963775), 'index': 53, 'word': '3', 'start': 211, 'end': 212}, {'entity': 'B-Date', 'score': np.float32(0.9913846), 'index': 56, 'word': '5', 'start': 217, 'end': 218}, {'entity': 'I-Date', 'score': np.float32(0.9983267), 'index': 57, 'word': 'weeks', 'start': 219, 'end': 224}, {'entity': 'B-Date', 'score': np.float32(0.9733446), 'index': 58, 'word': '6', 'start': 225, 'end': 226}, {'entity': 'I-Date', 'score': np.float32(0.996636), 'index': 59, 'word': 'days', 'start': 227, 'end': 231}, {'entity': 'B-Diagnostic_procedure', 'score': np.float32(0.99284196), 'index': 61, 'word': 'blood', 'start': 237, 'end': 242}, {'entity': 'I-Diagnostic_procedure', 'score': np.float32(0.9828979), 'index': 62, 'word': 'collection', 'start': 243, 'end': 253}, {'entity': 'B-Biological_structure', 'score': np.float32(0.87122697), 'index': 66, 'word': 'above', 'start': 267, 'end': 272}, {'entity': 'B-Disease_disorder', 'score': np.float32(0.701148), 'index': 67, 'word': 'internal', 'start': 273, 'end': 281}, {'entity': 'I-Biological_structure', 'score': np.float32(0.9359654), 'index': 68, 'word': 'loss', 'start': 282, 'end': 286}, {'entity': 'B-Area', 'score': np.float32(0.9706382), 'index': 70, 'word': '5', 'start': 297, 'end': 298}, {'entity': 'I-Area', 'score': np.float32(0.9687019), 'index': 71, 'word': '.', 'start': 298, 'end': 299}, {'entity': 'I-Area', 'score': np.float32(0.938197), 'index': 72, 'word': '9', 'start': 299, 'end': 300}, {'entity': 'I-Area', 'score': np.float32(0.97808164), 'index': 73, 'word': 'x', 'start': 301, 'end': 302}, {'entity': 'I-Area', 'score': np.float32(0.95591986), 'index': 74, 'word': '2', 'start': 303, 'end': 304}, {'entity': 'I-Area', 'score': np.float32(0.9877166), 'index': 75, 'word': '.', 'start': 304, 'end': 305}, {'entity': 'I-Area', 'score': np.float32(0.97562385), 'index': 76, 'word': '8', 'start': 305, 'end': 306}, {'entity': 'B-Biological_structure', 'score': np.float32(0.9953832), 'index': 79, 'word': 'ce', 'start': 311, 'end': 313}, {'entity': 'B-Biological_structure', 'score': np.float32(0.19974424), 'index': 80, 'word': '##r', 'start': 313, 'end': 314}, {'entity': 'I-Distance', 'score': np.float32(0.4452217), 'index': 81, 'word': '##vi', 'start': 314, 'end': 316}, {'entity': 'I-Distance', 'score': np.float32(0.45861337), 'index': 82, 'word': '##x', 'start': 316, 'end': 317}, {'entity': 'I-Area', 'score': np.float32(0.27698043), 'index': 83, 'word': '4', 'start': 318, 'end': 319}, {'entity': 'I-Area', 'score': np.float32(0.69440645), 'index': 84, 'word': 'cm', 'start': 320, 'end': 322}, {'entity': 'B-Sign_symptom', 'score': np.float32(0.9985), 'index': 92, 'word': 'free', 'start': 349, 'end': 353}, {'entity': 'I-Sign_symptom', 'score': np.float32(0.99956423), 'index': 93, 'word': 'fluid', 'start': 354, 'end': 359}, {'entity': 'B-Detailed_description', 'score': np.float32(0.95259804), 'index': 99, 'word': 'douglas', 'start': 380, 'end': 387}, {'entity': 'B-Coreference', 'score': np.float32(0.61190856), 'index': 103, 'word': 'ui', 'start': 408, 'end': 410}, {'entity': 'B-Coreference', 'score': np.float32(0.8619557), 'index': 104, 'word': '##g', 'start': 410, 'end': 411}, {'entity': 'B-Date', 'score': np.float32(0.99648917), 'index': 106, 'word': '30', 'start': 414, 'end': 416}, {'entity': 'I-Date', 'score': np.float32(0.9995684), 'index': 107, 'word': 'august', 'start': 417, 'end': 423}, {'entity': 'I-Date', 'score': np.float32(0.9996985), 'index': 108, 'word': '202', 'start': 424, 'end': 427}, {'entity': 'I-Date', 'score': np.float32(0.9998661), 'index': 109, 'word': '##5', 'start': 427, 'end': 428}]\n",
      "Extracted entities using d4data/biomedical-ner-all: [{'entity': 'early ob ste trics son ography', 'label': 'Diagnostic_procedure'}, {'entity': 'l mp', 'label': 'Diagnostic_procedure'}, {'entity': '15th november 202 4', 'label': 'Date'}, {'entity': 'ed d', 'label': 'Diagnostic_procedure'}, {'entity': '22nd august 202 5 d 7 weeks', 'label': 'Date'}, {'entity': 'avi', 'label': 'History'}, {'entity': 'ut erus', 'label': 'Biological_structure'}, {'entity': 'station al', 'label': 'Biological_structure'}, {'entity': 'fetal', 'label': 'Biological_structure'}, {'entity': 'dec', 'label': 'Diagnostic_procedure'}, {'entity': 'cr l', 'label': 'Diagnostic_procedure'}, {'entity': '3', 'label': 'Lab_value'}, {'entity': '5 weeks', 'label': 'Date'}, {'entity': '6 days', 'label': 'Date'}, {'entity': 'blood collection', 'label': 'Diagnostic_procedure'}, {'entity': 'above', 'label': 'Biological_structure'}, {'entity': 'internal', 'label': 'Disease_disorder'}, {'entity': '5 . 9 x 2 . 8', 'label': 'Area'}, {'entity': 'ce', 'label': 'Biological_structure'}, {'entity': 'r', 'label': 'Biological_structure'}, {'entity': 'free fluid', 'label': 'Sign_symptom'}, {'entity': 'douglas', 'label': 'Detailed_description'}, {'entity': 'ui', 'label': 'Coreference'}, {'entity': 'g', 'label': 'Coreference'}, {'entity': '30 august 202 5', 'label': 'Date'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated report for ClinicalBERT-NER: output_clinicalbert-ner.md, output_clinicalbert-ner.pdf\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import pypandoc\n",
    "import re\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# Download Pandoc if not already installed\n",
    "pypandoc.download_pandoc()\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device set to use {device}\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Define context for Ollama prompt\n",
    "context = '''\n",
    "Goal: Take anonymized audio notes and generate a structured report based on the extracted information. The report should resemble clinical notes as closely as possible, containing patient information, FINDINGS, and comments.\n",
    "\n",
    "You will be provided with the following examples:\n",
    "\n",
    "Four anonymized clinical notes from sonography sessions\n",
    "Corresponding anonymized audio notes (Note: Audio recordings may contain less information than the clinical notes).\n",
    "\n",
    "anonymized audio note1: Early pregnancy LMP 4th October 2024 EDD 11th July 2025 D5 week 6 days Single intrauterine gestational sac is seen Fetal pole is not seen yet YAC sac seen Decidual reaction present No membrane separation is seen MHD 1.45 mm 1.45 cm Maturity 5 weeks 5 days Right over in normal Left over in odd scene History of removal noted\n",
    "\n",
    "clinical note1: NAME:  DATE- 14 NOV 2024 SEX: FEMALE AGE: 31 YRS REF. BY:  UHID NO: 62576/ OP D EXAMINATION: GRAV IDU TERU S LMP- 04/10/2024 D- 5 W ks 6 Days EDD- 11/07/2025 FINDINGS:  The grav id uterus show' s smooth walled gestation al sac.  A yolk sac is seen. Foetal pole is not seen yet.  Decidual reaction seen.  No. membrane separation is seen.  MS D- 1.45 m D- 5 W ks 5 Days Right ovary normal.  Left ovary not seen. H/ O removal.  No aden ex al pathology seen.  No free fluid is seen in POD.  Comments: Early intra uterine pregnancy of age- 5 w ks 5 days\n",
    "\n",
    "anonymized audio note2: liver is normal both kidney are normal in size and echo and both ureter are not dilated urinary bladder is well distended no calculus or mass seen uterus is normal in size the myometrial and endometrial echo are normal the endometrial cavity is empty ET 6 mm both ovaries are normal and minimal free fluid in lower abdomen\n",
    "\n",
    "clinical note2: Name Date- 04 Dec 2024 Sex Female Age- 19 Yrs Ref. By Uni. ID- 86451/ IPD Examination: USG of Abdomen and Pelvis Findings:  The liver appears normal in size and echo. No focal or diffuse lesion is seen.  NoI HBR dilatation is seen. The portal and hepatic veins are normal.  The gall bladder is distended. No calculus or mass is seen. The wall thickness is normal.  CBD is of normal caliber.  Spleen is of normal size and echo. No focal or diffuse lesion seen.  Pancreas is normal in echo. The pancreatic duct is not dilated.  Both kidneys are normal in size and echo. The CM differentiation is preserved. No calculus or hydrone phrosis is seen. No perinephric pathology seen.  RK- 90 x 40 mm PT- 12 mm LK- 99 x 44 mm PT- 14 mm Both the ureters are not dilated.  Urinary bladder is well distended. No calculus or mass is seen.  Uterus is normal in size. The myometrial and endometrial echo are normal. The endometrial cavity is empty. ET- 6 mm.  Both ovaries are normal. No aden exal pathology is seen.  No lymph nodes seen. No obvious bowel lesion seen.  There is a minimal free fluid is seen in lower abdomen.  Comments:  Minimal free fluid in lower abdomen.  Clinical correlation and followup\n",
    "\n",
    "anonymized audio note3:  Single live intrauterine fetus is seen in URTEX presentation. Fetal cardiac activity and movements are appreciated. FHR 136 per minute, LICAR is less, AFI 8.6 cm, placenta is posterior, left lateral, 3 vessel cord is seen. called a scene the PD 8.66 HC 32.7 AC 30.6 T FL 6.62 HL 6.07 average 35 plus 2 weight 2 4 6 9 color Doppler examination within normal limits mild oligohydronius\n",
    "\n",
    "clinical note3: NAME:  DATE: 13 DEC 2024 SEX/ AGE: FEMALE/ 30 YRS REF. BY:  EXAM: OBSTETRICS USG LMP- 07/04/2024 D- 35 W KS 5 DAYS ED D- 12/01/2025 FINDINGS:  Single live intra ture r in e foe tus is seen in vertex presentation.  The foe tal cardiac activity and movements are appreciated. F HR- 136/ bpm.  Liquor is less. AFI- 8.6 cm.  Placenta is posterior, left lateral.  Three vessel cord is seen.  No obvious congenital anomalies are seen in the present foetal position.  Detection of anomalies depends upon the gestational age, foetal position.  amount of liquor and maternal abdominal wall thickness. Not all anomalies are detected on USG. Gender evaluation is not done as per the P CP ND T law.  The foetal parameters areas follows-  BPD 8.66 cm.  HC 32.70 cm.  AC 30.60 cm.  FL 6.62 cm.  HL 6.07 cm.  Average gestational age- 35 w ks 2 days EFB W- 2469 gm s± 10%  ART ER Y PI RI S/ D Umbilical 1.00 0.63 2.74 Right uter in e 0.61 0.40 1.67 Left uter in e 0.84 0.55 2.20 MCA 1.45 0.79 4.84 COMMENTS:  Single intra ture r in e foetus in vertex presentation with average gestational age of 35 w ks 2 days Less liquor.\n",
    "\n",
    "anonymized audio note4:  Pelvic Ultrasound Examination Uterus is bulky, globular and shows adenomyotic changes Majors 8.5 x 6.34 x 5.7 cm Endometrial equal central and normal, ET 6.6 Both ovaries normal, no adenoxyl pathology, no free fluid is seen in pouch of Douglas Adenomyosis uterus\n",
    "\n",
    "clinical note4: NAME SEX:  FEMALE DATE: 03 JAN 2024 REF. BY:  AGE: 22 YRS EXAMINATION: GRAV I DU TERU S UH ID NO: 80768/ OP D LMP- 15/11/2024 D- 7 W ks ED D- 22/08/2025 FINDINGS:  The gravid uterus shows smooth walled gestation al sac.  A foetal pole is seen.  Cardiac activity is appreciated.  Decidual reaction is good.  C RL- 3 mm D- 5 W ks 6 Days Tiny blood collection seen just above internal os, measuring 5.9 x 2.8 mm.  CER VIX- 4 cms No aden exal pathology seen.  No free fluid is seen in POD.  Comments:  Early intra uterine pregnancy of age- 5 W ks 6 Days Delayed conception. USG ED D- 30/08/2025 Tiny blood collection just above internal os.\n",
    "'''\n",
    "\n",
    "# Function to preprocess transcript text\n",
    "def preprocess_text(text, is_cased_model=False):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    if not is_cased_model:\n",
    "        text = text.lower()  # Convert to lowercase only for uncased models\n",
    "    return text\n",
    "\n",
    "# Function to extract entities using BERT-based models\n",
    "def extract_entities_with_bert(text, model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "    # Preprocess the text based on whether the model is cased\n",
    "    is_cased = \"cased\" in model_name.lower()\n",
    "    text = preprocess_text(text, is_cased_model=is_cased)\n",
    "    \n",
    "    # Perform NER and print raw output for debugging\n",
    "    raw_entities = nlp(text)\n",
    "    print(f\"Raw NER output from {model_name}: {raw_entities}\")\n",
    "    \n",
    "    # Post-process entities into a structured format\n",
    "    extracted_entities = []\n",
    "    current_entity = \"\"\n",
    "    current_label = \"\"\n",
    "    \n",
    "    for entity in raw_entities:\n",
    "        word = entity['word'].replace(\"##\", \"\")  # Handle subword tokens\n",
    "        if entity['entity'].startswith('B-'):\n",
    "            if current_entity:\n",
    "                extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "            current_entity = word\n",
    "            current_label = entity['entity'][2:]  # Remove 'B-' prefix\n",
    "        elif entity['entity'].startswith('I-') and current_label == entity['entity'][2:]:\n",
    "            current_entity += \" \" + word\n",
    "        else:\n",
    "            if current_entity:\n",
    "                extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "            current_entity = \"\"\n",
    "            current_label = \"\"\n",
    "\n",
    "    if current_entity:\n",
    "        extracted_entities.append({\"entity\": current_entity, \"label\": current_label})\n",
    "\n",
    "    return extracted_entities\n",
    "\n",
    "# Function to generate structured report using Ollama\n",
    "def generate_ollama(query, entities, model_name):\n",
    "    prompt = context\n",
    "    prompt += f\"\\n\\nTesting anonymized audio note: {query}\\n\\n\"\n",
    "    prompt += f\"Extracted entities by BERT model: {entities}\\n\\n\"\n",
    "    prompt += \"Give me the corresponding report with a clear Markdown style, for Testing anonymized audio note.\\n\"\n",
    "    prompt += \"The Markdown report starts with '$$$$$$' and ends with '@@@@@@'.\\n\"\n",
    "    response: ChatResponse = chat(model=model_name, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        },\n",
    "    ])\n",
    "\n",
    "    return response.message.content\n",
    "\n",
    "# Function to clean Markdown content\n",
    "def clean_markdown_content(text):\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    start_index = next((i for i, line in enumerate(lines) if \"$$$$$$\" in line), None)\n",
    "    end_index = next((i for i, line in enumerate(lines) if \"@@@@@@\" in line), None)\n",
    "\n",
    "    if end_index is not None:\n",
    "        lines = lines[:end_index]    \n",
    "    if start_index is not None:\n",
    "        lines = lines[start_index + 1:]\n",
    "\n",
    "    return '\\n'.join(lines).strip()\n",
    "\n",
    "# Main pipeline to process transcript, extract entities, and generate report\n",
    "def process_transcript(transcript_file, bert_model_name, ollama_model_name, output_md_file, output_pdf_file):\n",
    "    # Read the transcript file\n",
    "    with open(transcript_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    print(f\"Processing transcript: {content}\")  # Debug: Show the input\n",
    "\n",
    "    # Step 1: Extract entities using BERT-based model\n",
    "    entities = extract_entities_with_bert(content, bert_model_name)\n",
    "    print(f\"Extracted entities using {bert_model_name}: {entities}\")\n",
    "\n",
    "    # Step 2: Generate structured report using Ollama\n",
    "    output = generate_ollama(content, entities, ollama_model_name)\n",
    "    output = clean_markdown_content(output)\n",
    "\n",
    "    # Save the Markdown output\n",
    "    with open(output_md_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output)\n",
    "\n",
    "    # Convert Markdown to PDF\n",
    "    pypandoc.convert_file(output_md_file, \"pdf\", outputfile=output_pdf_file)\n",
    "\n",
    "# Define BERT models to use (using a clinical NER model)\n",
    "bert_models = {\n",
    "    \"ClinicalBERT-NER\": \"d4data/biomedical-ner-all\" # Fine-tuned for clinical NER\n",
    "}\n",
    "\n",
    "# Run the pipeline\n",
    "transcript_file = \"./anonymized/5.wav.txt\"  # Adjust path to your transcript file\n",
    "ollama_model = \"phi4:latest\"\n",
    "\n",
    "for bert_name, bert_model_name in bert_models.items():\n",
    "    output_md_file = f\"output_{bert_name.lower()}.md\"\n",
    "    output_pdf_file = f\"output_{bert_name.lower()}.pdf\"\n",
    "    print(f\"Processing with {bert_name}...\")\n",
    "    process_transcript(transcript_file, bert_model_name, ollama_model, output_md_file, output_pdf_file)\n",
    "    print(f\"Generated report for {bert_name}: {output_md_file}, {output_pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
